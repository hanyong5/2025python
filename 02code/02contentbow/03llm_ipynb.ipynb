{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-Fnso7YQjuh"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    \"나는 너 만나 사과를 먹으면서 너에게 잘못했던 문제에 대해서 사과를 했어\",\n",
        "    \"나는 사과를 먹으면서 너와 즐겁게 대화를 했어\",\n",
        "    \"나는 오늘 데이트를 했는데 사과나무를 봤어\",\n",
        "    \"어제 바나나를 먹었어\",\n",
        "    \"여름에 바나나보트를 탔어\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import torch\n",
        "import time"
      ],
      "metadata": {
        "id": "PF6xTX-YRltX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'device: {device}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-72un7AvR2Zc",
        "outputId": "c9851d5a-4631-459b-dbec-efcad5b8cf1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_with_retry(model_name, max_retries=3):\n",
        "    \"\"\"재시도 로직이 포함된 모델 로딩\"\"\"\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"모델 다운로드 시도 {attempt + 1}/{max_retries}...\")\n",
        "            model = SentenceTransformer(model_name)\n",
        "            print(\"✓ 모델 로딩 성공!\")\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"✗ 시도 {attempt + 1} 실패: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                time.sleep(5)  # 5초 대기 후 재시도\n",
        "            else:\n",
        "                raise"
      ],
      "metadata": {
        "id": "ZJTssd79xADO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_candidates = [\n",
        "    \"jhgan/ko-sroberta-multitask\",\n",
        "    \"BM-K/KoSimCSE-roberta-multitask\",\n",
        "    \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n",
        "]\n",
        "\n",
        "model = None\n",
        "\n",
        "\n",
        "# model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\").to(device)\n",
        "# model = SentenceTransformer(\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\").to(device)\n",
        "# model = SentenceTransformer(\"bert-base-multilingual-cased\").to(device)\n"
      ],
      "metadata": {
        "id": "o1YlrUXuxKOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name in model_candidates:\n",
        "    try:\n",
        "        print(f\"\\n'{model_name}' 로딩 시도 중...\")\n",
        "        model = load_model_with_retry(model_name)\n",
        "        print(f\"사용 모델: {model_name}\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"'{model_name}' 로딩 실패, 다음 모델 시도...\")\n",
        "        continue\n",
        "\n",
        "if model is None:\n",
        "    raise Exception(\"모든 모델 로딩 실패\")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHQs5uTCxNEt",
        "outputId": "7ff304ef-7e87-4cda-c36a-2c1490a7ef67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "'jhgan/ko-sroberta-multitask' 로딩 시도 중...\n",
            "모델 다운로드 시도 1/3...\n",
            "✓ 모델 로딩 성공!\n",
            "사용 모델: jhgan/ko-sroberta-multitask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc_emb = model.encode(docs,convert_to_tensor=True, normalize_embeddings=True).to(device)"
      ],
      "metadata": {
        "id": "UjZ_hBCAYTuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search(query:str,top_k:int=2):\n",
        "  q_emb = model.encode(query,convert_to_tensor=True, normalize_embeddings=True).to(device)\n",
        "  scores = util.cos_sim(q_emb, doc_emb)[0]\n",
        "  top= torch.topk(scores, k=top_k)\n",
        "  result = []\n",
        "  for score,idx in zip(top.values,top.indices):\n",
        "    result.append((float(score),docs[int(idx)]))\n",
        "  return result\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YXhYjsE5Yltw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query1 = \"대화\"\n",
        "print(f'{query1}')\n",
        "for s,text in search(query1):\n",
        "  print(f'{s} | {text}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQNcfl67aCNA",
        "outputId": "9f5452b2-4cbb-4ec5-f9bb-026ca9af9edf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "대화\n",
            "0.3656215965747833 | 나는 사과를 먹으면서 너와 즐겁게 대화를 했어\n",
            "0.24063296616077423 | 나는 너 만나 사과를 먹으면서 너에게 잘못했던 문제에 대해서 사과를 했어\n"
          ]
        }
      ]
    }
  ]
}